<?xml version="1.0" encoding="UTF-8"?>
<taskentries>
  <task>
    <url>/_dr/task/rdeStaging</url>
    <name>rdeStaging</name>
    <description>
      This job generates a full RDE escrow deposit as a single gigantic XML document
      and streams it to cloud storage. When this job has finished successfully, it'll
      launch a separate task that uploads the deposit file to Iron Mountain via SFTP.
    </description>
    <!--
      This only needs to run once per day, but we launch additional jobs in case the
      cursor is lagging behind, so it'll catch up to the current date as quickly as
      possible. The only job that'll run under normal circumstances is the one that's
      close to midnight, since if the cursor is up-to-date, the task is a no-op.
      We want it to be close to midnight because that reduces the chance that the
      point-in-time code won't have to go to the extra trouble of fetching old
      versions of objects from the database. However, we don't want it to run too
      close to midnight, because there's always a chance that a change which was
      timestamped before midnight hasn't fully been committed to the database. So
      we add a 4+ minute grace period to ensure the transactions cool down, since
      our queries are not transactional.
    -->
    <schedule>7 */8 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=rde-upload&endpoint=/_dr/task/rdeUpload&forEachRealTld]]></url>
    <name>rdeUpload</name>
    <description>
      This job is a no-op unless RdeUploadCursor falls behind for some reason.
    </description>
    <schedule>0 */4 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=rde-report&endpoint=/_dr/task/rdeReport&forEachRealTld]]></url>
    <name>rdeReport</name>
    <description>
      This job is a no-op unless RdeReportCursor falls behind for some reason.
    </description>
    <schedule>0 */4 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=marksdb&endpoint=/_dr/task/tmchDnl&runInEmpty]]></url>
    <name>tmchDnl</name>
    <description>
      This job downloads the latest DNL from MarksDB and inserts it into the database.
      (See: TmchDnlAction, ClaimsList)
    </description>
    <schedule>0 0,12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=marksdb&endpoint=/_dr/task/tmchSmdrl&runInEmpty]]></url>
    <name>tmchSmdrl</name>
    <description>
      This job downloads the latest SMDRL from MarksDB and inserts it into the database.
      (See: TmchSmdrlAction, SignedMarkRevocationList)
    </description>
    <schedule>15 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=marksdb&endpoint=/_dr/task/tmchCrl&runInEmpty]]></url>
    <name>tmchCrl</name>
    <description>
      This job downloads the latest CRL from MarksDB and inserts it into the database.
      (See: TmchCrlAction)
    </description>
    <schedule>0 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/syncGroupMembers&runInEmpty]]></url>
    <name>syncGroupMembers</name>
    <description>
      Syncs RegistrarContact changes in the past hour to Google Groups.
    </description>
    <schedule>0 */1 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=sheet&endpoint=/_dr/task/syncRegistrarsSheet&runInEmpty]]></url>
    <name>syncRegistrarsSheet</name>
    <description>
      Synchronize Registrar entities to Google Spreadsheets.
    </description>
    <schedule>0 */1 * * *</schedule>
  </task>

  <!-- TODO: @ptkach add resaveAllEppResourcesPipelineAction https://cs.opensource.google/nomulus/nomulus/+/master:core/src/main/java/google/registry/env/production/default/WEB-INF/cron.xml;l=105 -->

  <task>
    <url><![CDATA[/_dr/task/updateRegistrarRdapBaseUrls]]></url>
    <name>updateRegistrarRdapBaseUrls</name>
    <description>
      This job reloads all registrar RDAP base URLs from ICANN.
    </description>
    <schedule>34 2 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/exportDomainLists&runInEmpty]]></url>
    <name>exportDomainLists</name>
    <description>
      This job exports lists of all active domain names to Google Drive and Google Cloud Storage.
    </description>
    <schedule>0 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/task/expandRecurringBillingEvents?advanceCursor]]></url>
    <name>expandRecurringBillingEvents</name>
    <description>
      This job runs an action that creates synthetic OneTime billing events from Recurring billing
      events. Events are created for all instances of Recurring billing events that should exist
      between the RECURRING_BILLING cursor's time and the execution time of the action.
    </description>
    <schedule>0 3 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/task/deleteExpiredDomains]]></url>
    <name>deleteExpiredDomains</name>
    <description>
      This job runs an action that deletes domains that are past their
      autorenew end date.
    </description>
    <schedule>7 3 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/task/sendExpiringCertificateNotificationEmail]]></url>
    <name>sendExpiringCertificateNotificationEmail</name>
    <description>
      This job runs an action that sends emails to partners if their certificates are expiring soon.
    </description>
    <schedule>30 4 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=nordn&endpoint=/_dr/task/nordnUpload&forEachRealTld&lordnPhase=sunrise]]></url>
    <name>nordnUploadSunrise</name>
    <description>
      This job uploads LORDN Sunrise CSV files for each TLD to MarksDB. It should be
      run at most every three hours, or at absolute minimum every 26 hours.
    </description>
    <!-- This may be set anywhere between "every 3 hours" and "every 25 hours". -->
    <schedule>0 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=nordn&endpoint=/_dr/task/nordnUpload&forEachRealTld&lordnPhase=claims]]></url>
    <name>nordnUploadClaims</name>
    <description>
      This job uploads LORDN Claims CSV files for each TLD to MarksDB. It should be
      run at most every three hours, or at absolute minimum every 26 hours.
    </description>
    <!-- This may be set anywhere between "every 3 hours" and "every 25 hours". -->
    <schedule>0 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=nordn&endpoint=/_dr/task/nordnUpload&forEachRealTld&lordnPhase=sunrise&pullQueue]]></url>
    <name>nordnUploadSunrisePullQueue</name>
    <description>
      This job uploads LORDN Sunrise CSV files for each TLD to MarksDB using
      pull queue. It should be run at most every three hours, or at absolute
      minimum every 26 hours.
    </description>
    <!-- This may be set anywhere between "every 3 hours" and "every 25 hours". -->
    <schedule>0 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=nordn&endpoint=/_dr/task/nordnUpload&forEachRealTld&lordnPhase=claims&pullQueue]]></url>
    <name>nordnUploadClaimsPullQueue</name>
    <description>
      This job uploads LORDN Claims CSV files for each TLD to MarksDB using pull
      queue. It should be run at most every three hours, or at absolute minimum
      every 26 hours.
    </description>
    <!-- This may be set anywhere between "every 3 hours" and "every 25 hours". -->
    <schedule>0 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/deleteProberData&runInEmpty]]></url>
    <name>deleteProberData</name>
    <description>
      This job clears out data from probers and runs once a week.
    </description>
    <schedule>0 14 * * 1</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/exportReservedTerms&forEachRealTld]]></url>
    <name>exportReservedTerms</name>
    <description>
      Reserved terms export to Google Drive job for creating once-daily exports.
    </description>
    <schedule>30 5 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/exportPremiumTerms&forEachRealTld]]></url>
    <name>exportPremiumTerms</name>
    <description>
      Exports premium price lists to the Google Drive folders for each TLD once per day.
    </description>
    <schedule>0 5 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/readDnsQueue?jitterSeconds=45]]></url>
    <name>readDnsQueue</name>
    <description>
      Lease all tasks from the dns-pull queue, group by TLD, and invoke PublishDnsUpdates for each
      group.
    </description>
    <schedule>*/1 * * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/icannReportingStaging&runInEmpty]]></url>
    <name>icannReportingStaging</name>
    <description>
      Create ICANN activity and transaction reports for last month, storing them in
      gs://[PROJECT-ID]-reporting/icann/monthly/yyyy-MM
      Upon success, enqueues the icannReportingUpload task to POST these files to ICANN.
    </description>
    <schedule>0 9 2 * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/icannReportingUpload&runInEmpty]]></url>
    <name>icannReportingUpload</name>
    <description>
      Checks if the monthly ICANN reports have been successfully uploaded. If they have not, attempts to upload them again.
      Most of the time, this job should not do anything since the uploads are triggered when the reports are staged.
      However, in the event that an upload failed for any reason (e.g. ICANN server is down, IP allow list issues),
      this cron job will continue to retry uploads daily until they succeed.
    </description>
    <schedule>0 15 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/generateInvoices?shouldPublish=true&runInEmpty]]></url>
    <name>generateInvoices</name>
    <description>
      Starts the beam/billing/InvoicingPipeline Dataflow template, which creates the overall invoice and
      detail report CSVs for last month, storing them in gs://[PROJECT-ID]-billing/invoices/yyyy-MM.
      Upon success, sends an e-mail copy of the invoice to billing personnel, and copies detail
      reports to the associated registrars' drive folders.
      See GenerateInvoicesAction for more details.
    </description>
    <!--WARNING: This must occur AFTER expandRecurringBillingEvents and AFTER exportSnapshot, as
    it uses Bigquery as the source of truth for billable events. ExportSnapshot usually takes
    about 2 hours to complete, so we give 11 hours to be safe. Normally, we give 24+ hours (see
    icannReportingStaging), but the invoicing team prefers receiving the e-mail on the first of
    each month. -->
    <schedule>0 19 1 * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/generateSpec11&runInEmpty]]></url>
    <name>generateSpec11</name>
    <description>
      Starts the beam/spec11/Spec11Pipeline Dataflow template, which creates today's Spec11
      report. This report is stored in gs://[PROJECT-ID]-reporting/icann/spec11/yyyy-MM/.
      This job will only send email notifications on the second of every month.
      See GenerateSpec11ReportAction for more details.
    </description>
    <schedule>0 15 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/task/wipeOutContactHistoryPii]]></url>
    <name>wipeOutContactHistoryPii</name>
    <description>
      This job runs weekly to wipe out PII fields of ContactHistory entities
      that have been in the database for a certain period of time.
    </description>
    <schedule>0 15 * * 1</schedule>
  </task>
</taskentries>
